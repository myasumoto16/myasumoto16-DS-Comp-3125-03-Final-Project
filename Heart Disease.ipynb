{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Indicator Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Objective:** Explore possible indicators for heart diseases.\n",
    "\n",
    "**Questions:**\n",
    "1. Which age range are you most likely to have heart issues?\n",
    "2. Do the smoking habits differ between people with and without heart issues?\n",
    "3. Which machine learning model among LogisticRegression, XGBClassifier, KNeighborsClassifier is the most suitable for predicting heart issues?\n",
    "\n",
    "\n",
    "## Selection of Datasets\n",
    "\n",
    "**DataSet:** 'Heart Disease Health Indicators Dataset' from Kaggle.\n",
    "\n",
    "**Data:**\n",
    "- [Heart Disease Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset)\n",
    "    - This is a cleaned and filtered dataset that is specific to heart disease in 2015. \n",
    "    - 253,680 survey responses from cleaned BRFSS 2015 dataset.\n",
    "    - Optimized for binary classifications for heart disease. '\n",
    "    - Strong class imbalance. \n",
    "        - 229,787 people have not had heart disease while 23,893 have had heart disease.\n",
    "\n",
    "\n",
    "- Original Dataset [Behavioral Risk Factor Surveillance System](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system)\n",
    "  - Public health surveys of more than 400,000 people from 2011 to 2015\n",
    "   - Data on preventive health practices and behaviors that are linked to chronic diseases, injuries, and preventable infectious diseases in the adult population.\n",
    "    - Collected by Center for Disease and Prevention\n",
    "\n",
    "## Methodologies\n",
    "\n",
    "### 1. Data Import and Cleaning\n",
    "\n",
    "- Use Pandas to:\n",
    "  - Import and filter dataset.\n",
    "  - Apply `groupby()` method for grouping certain rows based on a value of another column \n",
    "- Use Matplotlib and seaborn for visualization.\n",
    "  - Used to plot bar graphs and pie charts for Q1 and Q2.\n",
    "  - Used to plot the confusion matrices for Q3. \n",
    "\n",
    "### 2. Machine Learning Models\n",
    "\n",
    "- For Q3, \"Which machine learning model among LogisticRegression, XGBClassifier, DecisionTreeClassifier is the most suitable for predicting heart issues?\"\n",
    "- Sklearn models below were picked based on their suitability for binary classifications:\n",
    "\n",
    "#### 2.1. Logistic Regression\n",
    "\n",
    "- Models the probability that a given instance belongs to a particular class.\n",
    "- Ideal for binary classification tasks.\n",
    "- Well-suited for linear relationships, provides interpretable coefficients, and outputs probabilities.\n",
    "- Considerations: Assumes a linear relationship between features and log-odds, which might limit its ability to analyze non-linear patterns.\n",
    "  \n",
    "#### 2.2. XGBClassifier (XGBoost)\n",
    "\n",
    "- Gradient boosting framework that builds a group of weak learners.\n",
    "- Well-suited for binary classification tasks and often outperforms other algorithms.\n",
    "- High predictive performance, handles non-linear relationships well, and includes regularization to prevent overfitting.\n",
    "- Considerations: May require tuning of hyperparameters.\n",
    "\n",
    "#### 2.3. DecisionTreeClassifier\n",
    "- Supervised learning algorithm that constructs a tree structure to make predictions based on feature conditions.\n",
    "- Well-suited for binary classification tasks due to its ability to create decision boundaries based on feature conditions.\n",
    "- Assumes axis-aligned decision boundaries, potentially limiting its ability to capture complex, non-linear patterns.\n",
    "- \n",
    "### 3. Dataset Division:\n",
    "\n",
    "  - Train (90%) and test (10%) subsets.\n",
    "  - Input and output sets.\n",
    "    - Predicting the output ['HeartDiseaseorAttack'] based on the input set. \n",
    "    - Input: ['HighBP,\tHighChol,\tCholCheck,\tBMI,\tSmoker,\tStroke,\tDiabetes,\tPhysActivity,\tHvyAlcoholConsump,\tAnyHealthcare,\tNoDocbcCost,\tGenHlth\tMentHlth,\tPhysHlth,\tDiffWalk,\tSex,\tAge']\n",
    "        - Columns used for the input set are chosen based on information that is commonly asked or measured at doctor's visits. \n",
    "        - Columns that are ignored are ['Fruits', 'Veggies', 'Education', 'Income']\n",
    "    - Output: ['HeartDiseaseorAttack']\n",
    "  \n",
    "### 4. Handling Imbalance: \n",
    "\n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique):**\n",
    "    - addresses class imbalance in binary classification tasks.\n",
    "    - designed for the minority class, SMOTE generates synthetic. \n",
    "    - By introducing synthetic examples, SMOTE helps balance class distribution, enhancing the model's ability to learn from the minority class and improving overall classification performance. \n",
    "        \n",
    "### 5. Evaluation Metrics with report:\n",
    "\n",
    "The classification report provides performance metrics for a binary classification model. Each row represents a class (0 or 1), and the columns include precision, recall, and F1-score. \n",
    "\n",
    "- **Precision:** The ratio of true positive predictions to the total predicted positives, indicating the accuracy of positive predictions.\n",
    "- **Recall:** The ratio of true positive predictions to the total actual positives, measuring the model's ability to capture all positive instances.\n",
    "- **F1-score:** The harmonic mean of precision and recall, offering a balanced assessment of a model's performance.\n",
    "\n",
    "\n",
    "### 6. Visualization with Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that provides a detailed summary of the performance of a classification model. It compares predicted labels against actual labels, categorizing instances into four outcomes:\n",
    "\n",
    "- **True Positive (TP):** Instances correctly predicted as positive.\n",
    "- **True Negative (TN):** Instances correctly predicted as negative.\n",
    "- **False Positive (FP):** Instances incorrectly predicted as positive.\n",
    "- **False Negative (FN):** Instances incorrectly predicted as negative.\n",
    "\n",
    "## Results\n",
    "- **Disclaimer**: To run the code, go to Kernal -> Restart & Run All. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# import the data\n",
    "data = pd.read_csv('heart_disease_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Which age range are you most likely to have heart issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only choosing rows that have the condition 'HeartDiseaseorAttack' == 1\n",
    "heart_disease_data = data[data['HeartDiseaseorAttack'] == 1]\n",
    "\n",
    "# Avoiding SettingWithCopyWarning\n",
    "heart_disease_data = heart_disease_data.copy()\n",
    "\n",
    "# Mapping the age numbers from 1 to 14 to Age ranges\n",
    "heart_disease_data['Age_Range'] = pd.cut(\n",
    "    data['Age'],\n",
    "    bins=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    labels=[\n",
    "        'Age 18-24', 'Age 25-29', 'Age 30-34', 'Age 35-39', 'Age 40-44',\n",
    "        'Age 45-49', 'Age 50-54', 'Age 55-59', 'Age 60-64', 'Age 65-69',\n",
    "        'Age 70-74', 'Age 75-79', 'Age 80 or older'\n",
    "    ],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "\n",
    "# Group by 'Age_Range' and count the frequency of 'HeartDiseaseorAttack = 1'\n",
    "frequency_by_age = heart_disease_data.groupby('Age_Range').size().reset_index(name='Frequency')\n",
    "\n",
    "print(frequency_by_age)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot with rotated x-axis labels\n",
    "plt.figure(figsize=(12, 6), dpi=400)\n",
    "ax = sns.barplot(x='Age_Range', y='Frequency', data=frequency_by_age, palette='viridis')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.title('Frequency of Heart Disease by Age Range')\n",
    "plt.xlabel('Age Range')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Do the smoking habits differ between people with and without heart issues?\n",
    "\n",
    "- Helper function to plot the pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_pie_chart(percentage_by_smoker, name):\n",
    "    # Pie chart\n",
    "    labels = percentage_by_smoker.index\n",
    "    sizes = percentage_by_smoker.values\n",
    "    colors = ['lightcoral', 'lightskyblue']\n",
    "    \n",
    "    plt.figure(figsize=(3,3), dpi=200)\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title('Percentage of Smokers ' + name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. How many people with a heart disease smoke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row where the HeartDiseaseorAttack is 1\n",
    "heart_disease_data = data[data['HeartDiseaseorAttack'] == 1]\n",
    "\n",
    "# Replace binary values with readable representations\n",
    "heart_disease_data['Smoker_Label'] = heart_disease_data['Smoker'].map({1.0: 'Smoker', 0.0: 'Non-Smoker'})\n",
    "\n",
    "# Group the dataset based on the Smoke_Label column \n",
    "frequency_by_smoker = heart_disease_data.groupby('Smoker_Label').size().reset_index(name='Frequency')\n",
    "\n",
    "# Calculate percentages\n",
    "total_cases = len(heart_disease_data)\n",
    "percentage_by_smoker = heart_disease_data.groupby('Smoker_Label').size() / total_cases * 100\n",
    "\n",
    "plot_pie_chart(percentage_by_smoker, 'with a Heart Disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. How many people without a heart disease smoke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row where the HeartDiseaseorAttack is 0\n",
    "non_heart_disease_data = data[data['HeartDiseaseorAttack'] == 0]\n",
    "\n",
    "# Replace binary values with readable representations\n",
    "non_heart_disease_data['Smoker_Label'] = non_heart_disease_data['Smoker'].map({1.0: 'Smoker', 0.0: 'Non-Smoker'})\n",
    "\n",
    "# Calculate percentages\n",
    "total_cases = len(heart_disease_data)\n",
    "percentage_by_smoker = non_heart_disease_data.groupby('Smoker_Label').size() / total_cases * 100\n",
    "\n",
    "plot_pie_chart(percentage_by_smoker, 'without a Heart Disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Can we accurately predict the anxiety, depression, and insomnia level based on their music taste or frequency using machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix of a given model and predictions\n",
    "def visualize_performance(y_true, y_pred):\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4.5), dpi=200)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def test_model(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Compute the accuracy score of the prediction\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "        \n",
    "    return [predictions, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Saving models\n",
    "- Below code was used to create, train and save models so the models won't have to be created every time we test them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Create and train a model based on given inputset and output set and specified machine learning model \n",
    "def create_train_and_save_model(X, y, model, file):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Apply SMOTE to the training set.\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Train your machine learning model on the resampled training set.\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    joblib.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was run to create and save models as joblib files\n",
    "# It is not run when executing Restart & Run All\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "def create_save_models():\n",
    "\n",
    "    # Extract input set (X) and output set (y)\n",
    "    X = data.drop(['HeartDiseaseorAttack', 'Education', 'Income', 'Fruits', 'Veggies'], axis=1)\n",
    "    y = data['HeartDiseaseorAttack']\n",
    "\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    create_train_and_save_model(X, y, model, 'LogisticRegression.joblib')\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    create_train_and_save_model(X, y, model, 'XGBClassifier.joblib')\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    create_train_and_save_model(X, y, model, 'DecisionTreeClassifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Extract input set (X) and output set (y)\n",
    "X = data.drop(['HeartDiseaseorAttack', 'Education', 'Income', 'Fruits', 'Veggies'], axis=1)\n",
    "y = data['HeartDiseaseorAttack']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = joblib.load('LogisticRegression.joblib')\n",
    "\n",
    "predictions, y_test = test_model(X_test, y_test, model)\n",
    "report = visualize_performance(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. XBGClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Extract input set (X) and output set (y)\n",
    "X = data.drop(['HeartDiseaseorAttack', 'Education', 'Income', 'Fruits', 'Veggies'], axis=1)\n",
    "y = data['HeartDiseaseorAttack']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = joblib.load('XGBClassifier.joblib')\n",
    "\n",
    "predictions, y_test = test_model(X_test, y_test, model)\n",
    "report = visualize_performance(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Extract input set (X) and output set (y)\n",
    "X = data.drop(['HeartDiseaseorAttack', 'Education', 'Income', 'Fruits', 'Veggies'], axis=1)\n",
    "y = data['HeartDiseaseorAttack']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = joblib.load('DecisionTreeClassifier.joblib')\n",
    "\n",
    "predictions, y_test = test_model(X_test, y_test, model)\n",
    "report = visualize_performance(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
